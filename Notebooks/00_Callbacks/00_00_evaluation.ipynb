{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp callbacks.evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "> Simple callbacks to evaluate the current training model on a dataset at different training times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Dict\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to build a class that stores a given dataset and calls evaluate on the training model when needed to obtain the evaluation metrics. We want it to be flexible in a way that we can specify a number of epochs or batches as the evaluation frequency. This could be solved by having a different callback for epoch and batches, but we probably can get away with using only one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class EvaluateDataset(Callback):\n",
    "    \"\"\"Evaluates a given `tf.data.Dataset` at different training times.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataset, # Dataset to be evaluated.\n",
    "                 freq_epochs=None, # Number of epochs to wait between evaluations. `None` means not evaluating at an epoch interval.\n",
    "                 freq_batches=None, # Number of batches to wait between evaluations. `None` means not evaluating at a batch interval.\n",
    "                 append=\"\", # Text to append to the metrics' names as an identifier.\n",
    "                 ):\n",
    "        self.dataset = dataset if isinstance(dataset, tf.data.Dataset) else self._convert_to_dataset(dataset)\n",
    "        self.freq_epochs = freq_epochs\n",
    "        self.freq_batches = freq_batches\n",
    "        self.append = append\n",
    "        self.batches_seen, self.epochs_seen = 0, 0\n",
    "        self._results_batches, self._results_epochs = [], []\n",
    "\n",
    "    def _convert_to_dataset(self,\n",
    "                            dataset, # Dataset to be converted.\n",
    "                            ):\n",
    "        \"\"\"Tries to convert a dataset into a `tf.data.Dataset`.\"\"\"\n",
    "        return dataset\n",
    "\n",
    "    def evaluate(self,\n",
    "                 ) -> Dict: # Dictionary of evaluation results.\n",
    "        \"\"\"Calls the `.evaluate()` method of the given `model` on the stored `dataset`.\"\"\"\n",
    "        return {f\"{name}{self.append}\": value for name, value in self.model.evaluate(self.dataset, verbose=0, return_dict=True).items()}\n",
    "\n",
    "    def on_train_batch_end(self,\n",
    "                           batch, # Batch number in an epoch.\n",
    "                           logs=None, # Training logs.\n",
    "                           ):\n",
    "\n",
    "        if self.freq_batches is None: return\n",
    "        else:\n",
    "            if self.batches_seen % self.freq_batches == 0: \n",
    "                results = self.evaluate()\n",
    "                self._results_batches.append(results)\n",
    "            self.batches_seen += 1\n",
    "    \n",
    "    def on_epoch_end(self,\n",
    "                     batch, # Batch number in an epoch.\n",
    "                     logs=None, # Training logs.\n",
    "                     ):\n",
    "        if self.freq_epochs is None: return\n",
    "        else:\n",
    "            if self.epochs_seen % self.freq_epochs == 0: \n",
    "                results = self.evaluate()\n",
    "                self._results_epochs.append(results)\n",
    "            self.epochs_seen += 1\n",
    "    \n",
    "    @staticmethod\n",
    "    def _unpack_list_dicts(list_of_dicts):\n",
    "        \"\"\"Unpacks a list of dicts sharing keys into a dict with lists as values.\"\"\"\n",
    "        res = {}\n",
    "        for result in list_of_dicts:\n",
    "            for metric, value in result.items():\n",
    "                if metric not in res.keys(): res[metric] = []\n",
    "                res[metric].append(value)\n",
    "        return res\n",
    "\n",
    "    @property\n",
    "    def results_batches(self):\n",
    "        if len(self._results_batches) == 0: raise ValueError(\"No values stored yet.\")\n",
    "        return self._unpack_list_dicts(self._results_batches)\n",
    "\n",
    "    @property\n",
    "    def results_epochs(self):\n",
    "        if len(self._results_epochs) == 0: raise ValueError(\"No values stored yet.\")\n",
    "        return self._unpack_list_dicts(self._results_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from iqadatasets.datasets.tid2013 import TID2013\n",
    "from iqadatasets.datasets.tid2008 import TID2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "tid13 = TID2013(\"/media/disk/databases/BBDD_video_image/Image_Quality/TID/TID2013\")\n",
    "tid08 = TID2013(\"/media/disk/databases/BBDD_video_image/Image_Quality/TID/TID2008\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from perceptnet.networks import PerceptNet\n",
    "from perceptnet.pearson_loss import PearsonCorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 12:32:23.207120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2373 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 780 Ti, pci bus id: 0000:02:00.0, compute capability: 3.5\n",
      "2022-11-07 12:32:23.209164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10793 MB memory:  -> device: 1, name: Tesla K40m, pci bus id: 0000:03:00.0, compute capability: 3.5\n",
      "2022-11-07 12:32:23.210353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 5435 MB memory:  -> device: 2, name: NVIDIA GeForce GTX TITAN Black, pci bus id: 0000:83:00.0, compute capability: 3.5\n",
      "2022-11-07 12:32:23.211964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 5435 MB memory:  -> device: 3, name: NVIDIA GeForce GTX TITAN Black, pci bus id: 0000:84:00.0, compute capability: 3.5\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "model = PerceptNet(kernel_initializer=\"ones\", gdn_kernel_size=1, learnable_undersampling=False)\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=PearsonCorrelation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 12:32:23.454509: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 12:32:26.883482: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100\n",
      "2022-11-07 12:32:27.433804: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-07 12:32:28.139269: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-11-07 12:32:28.232115: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-11-07 12:32:28.240635: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-11-07 12:32:28.440640: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-11-07 12:32:28.460049: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-11-07 12:32:28.680518: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.40GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6/Unknown - 9s 768ms/step - loss: -0.7324WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3184s vs `on_train_batch_end` time: 0.5511s). Check your callbacks.\n",
      "10/10 [==============================] - 12s 738ms/step - loss: -0.8586\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 6s 668ms/step - loss: -0.8743\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "cb_eval = EvaluateDataset(tid13.dataset.batch(16).take(4), freq_batches=5, append=\"_TID2013\")\n",
    "history = model.fit(tid08.dataset.batch(16).take(10), epochs=2, callbacks=[cb_eval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_TID2013': [-0.8481918573379517,\n",
       "  -0.8950705528259277,\n",
       "  -0.88816237449646,\n",
       "  -0.9112398624420166]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "cb_eval.results_batches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gpu')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
