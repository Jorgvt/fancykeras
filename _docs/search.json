[
  {
    "objectID": "00_Callbacks/evaluation.html",
    "href": "00_Callbacks/evaluation.html",
    "title": "Evaluation",
    "section": "",
    "text": "EvaluateDataset\n\n EvaluateDataset (dataset, freq_epochs=None, freq_batches=None, append='')\n\nEvaluates a given tf.data.Dataset at different training times.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndataset\n\n\nDataset to be evaluated.\n\n\nfreq_epochs\nNoneType\nNone\nNumber of epochs to wait between evaluations. None means not evaluating at an epoch interval.\n\n\nfreq_batches\nNoneType\nNone\nNumber of batches to wait between evaluations. None means not evaluating at a batch interval.\n\n\nappend\nstr\n\nText to append to the metrics’ names as an identifier.\n\n\n\n\nfrom iqadatasets.datasets.tid2013 import TID2013\nfrom iqadatasets.datasets.tid2008 import TID2008\n\n\ntid13 = TID2013(\"/media/disk/databases/BBDD_video_image/Image_Quality/TID/TID2013\")\ntid08 = TID2013(\"/media/disk/databases/BBDD_video_image/Image_Quality/TID/TID2008\")\n\n\nfrom perceptnet.networks import PerceptNet\nfrom perceptnet.pearson_loss import PearsonCorrelation\n\n\nmodel = PerceptNet(kernel_initializer=\"ones\", gdn_kernel_size=1, learnable_undersampling=False)\nmodel.compile(optimizer=\"adam\",\n              loss=PearsonCorrelation())\n\n2022-11-07 12:32:23.207120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2373 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 780 Ti, pci bus id: 0000:02:00.0, compute capability: 3.5\n2022-11-07 12:32:23.209164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10793 MB memory:  -> device: 1, name: Tesla K40m, pci bus id: 0000:03:00.0, compute capability: 3.5\n2022-11-07 12:32:23.210353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 5435 MB memory:  -> device: 2, name: NVIDIA GeForce GTX TITAN Black, pci bus id: 0000:83:00.0, compute capability: 3.5\n2022-11-07 12:32:23.211964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 5435 MB memory:  -> device: 3, name: NVIDIA GeForce GTX TITAN Black, pci bus id: 0000:84:00.0, compute capability: 3.5\n\n\n\ncb_eval = EvaluateDataset(tid13.dataset.batch(16).take(4), freq_batches=5, append=\"_TID2013\")\nhistory = model.fit(tid08.dataset.batch(16).take(10), epochs=2, callbacks=[cb_eval])\n\n2022-11-07 12:32:23.454509: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n\n\nEpoch 1/2\n\n\n2022-11-07 12:32:26.883482: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100\n2022-11-07 12:32:27.433804: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n2022-11-07 12:32:28.139269: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n2022-11-07 12:32:28.232115: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n2022-11-07 12:32:28.240635: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n2022-11-07 12:32:28.440640: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n2022-11-07 12:32:28.460049: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n2022-11-07 12:32:28.680518: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.40GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n\n\n      6/Unknown - 9s 768ms/step - loss: -0.7324WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3184s vs `on_train_batch_end` time: 0.5511s). Check your callbacks.\n10/10 [==============================] - 12s 738ms/step - loss: -0.8586\nEpoch 2/2\n10/10 [==============================] - 6s 668ms/step - loss: -0.8743\n\n\n\ncb_eval.results_batches\n\n{'loss_TID2013': [-0.8481918573379517,\n  -0.8950705528259277,\n  -0.88816237449646,\n  -0.9112398624420166]}"
  },
  {
    "objectID": "02_Layers/skip_connection.html",
    "href": "02_Layers/skip_connection.html",
    "title": "Skip connection",
    "section": "",
    "text": "SkipConnection\n\n SkipConnection (*args, **kwargs)\n\nSkip connection layer to easily introduce this architecture without moving away from the Sequential model.\n\nmodel = tf.keras.Sequential([\n    layers.Dense(30, input_shape=(50,)),\n    SkipConnection(main_path=tf.keras.Sequential([layers.Dense(15), layers.Dense(30)]))\n])\nassert model.output_shape[-1] == 30\nmodel.summary()\n\nModel: \"sequential_21\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_29 (Dense)            (None, 30)                1530      \n                                                                 \n skip_connection_9 (SkipConn  (None, 30)               945       \n ection)                                                         \n                                                                 \n=================================================================\nTotal params: 2,475\nTrainable params: 2,475\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nsample_input = tf.random.normal(shape=(32,50))\nsample_output = model.predict(sample_input, verbose=0)\nassert sample_output.shape == (32,30)\n\n\nmodel = tf.keras.Sequential([\n    layers.Dense(30, input_shape=(50,)),\n    SkipConnection(main_path=tf.keras.Sequential([layers.Dense(15), layers.Dense(30)]), how=\"concat\")\n])\nassert model.output_shape[-1] == 60\nmodel.summary()\n\nModel: \"sequential_23\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_32 (Dense)            (None, 30)                1530      \n                                                                 \n skip_connection_10 (SkipCon  (None, 60)               945       \n nection)                                                        \n                                                                 \n=================================================================\nTotal params: 2,475\nTrainable params: 2,475\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nsample_input = tf.random.normal(shape=(32,50))\nsample_output = model.predict(sample_input, verbose=0)\nassert sample_output.shape == (32,60)"
  },
  {
    "objectID": "01_SelfSupervised/jigsaw_puzzle.html",
    "href": "01_SelfSupervised/jigsaw_puzzle.html",
    "title": "Jigsaw Puzzle",
    "section": "",
    "text": "This could be implemented as a function that uses out of scope variables, but as we want to have everything as packed as possible, we’re going to define a class that stores the possible combinations and the methods needed to invert the permutations in order to de-puzzle a puzzled image."
  },
  {
    "objectID": "01_SelfSupervised/jigsaw_puzzle.html#using-it-with-a-tf.data.dataset",
    "href": "01_SelfSupervised/jigsaw_puzzle.html#using-it-with-a-tf.data.dataset",
    "title": "Jigsaw Puzzle",
    "section": "Using it with a tf.data.Dataset",
    "text": "Using it with a tf.data.Dataset\n\ndef sample_dataset():\n    for i in range(20):\n        red = np.ones(shape=(16,16,3))*np.array([255,0,0])[None,None,:]\n        blue = np.ones(shape=(16,16,3))*np.array([0,255,0])[None,None,:]\n        green = np.ones(shape=(16,16,3))*np.array([0,0,255])[None,None,:]\n        white = np.ones(shape=(16,16,3))*np.array([255,255,255])[None,None,:]\n        red_blue = np.concatenate([red, blue], axis=1)\n        green_white = np.concatenate([green, white], axis=1)\n        img = np.concatenate([red_blue, green_white], axis=0)\n        yield img\n\n\ndst = tf.data.Dataset.from_generator(sample_dataset,\n                                     output_signature=(\n                                        tf.TensorSpec(shape=(32,32,3), dtype=tf.float32)\n                                     ))\npuzler = JigsawPuzzle(n_tiles=4)\ndst_puzzle = dst.map(puzler.make_puzzle)\n\n\nfor img in dst:\n    print(img.shape)\n    break\nplt.imshow(img)\nplt.show()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n(32, 32, 3)\n\n\n\n\n\n\nfor img, perm in dst_puzzle:\n    print(img.shape)\n    break\nperm = puzler.labels2permutations[perm.numpy()]\nimg_ = puzler.invert_puzzle(img, perm)\nplt.imshow(puzler.assemble_puzzle(img))\nplt.title(perm)\nplt.show()\nplt.imshow(img_)\nplt.show()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n(4, 16, 16, 3)\n\n\n\n\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "fancykeras",
    "section": "",
    "text": "This file will become your README and also the index of your documentation."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "fancykeras",
    "section": "Install",
    "text": "Install\npip install fancykeras"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "fancykeras",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2"
  }
]